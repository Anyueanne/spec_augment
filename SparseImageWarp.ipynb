{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow's `sparse_image_warp` in Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first call `%store spectro` in the other notebook to save spectro value here\n",
    "%store -r spectro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source_control_point_locations: `[batch, num_control_points, 2]` float\n",
    "#   `Tensor`\n",
    "# dest_control_point_locations: `[batch, num_control_points, 2]` float\n",
    "#   `Tensor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_dimensions = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paper says 'a random point' so we'll use 1 num_control_point\n",
    "src_pts, dest_pts = torch.tensor([[[1,3]]]), torch.tensor([[[1,6]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128, 1718])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spectro.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_image_warp(img_tensor:torch.Tensor,\n",
    "                      source_control_point_locations:torch.Tensor,\n",
    "                      dest_control_point_locations:torch.Tensor,\n",
    "                      interpolation_order=2,\n",
    "                      regularization_weight=0.0,\n",
    "                      num_boundaries_points=0):\n",
    "    control_point_flows = (dest_control_point_locations - source_control_point_locations)\n",
    "    \n",
    "#     clamp_boundaries = num_boundary_points > 0\n",
    "#     boundary_points_per_edge = num_boundary_points - 1\n",
    "    batch_size, image_height, image_width = img_tensor.shape\n",
    "    grid_locations = get_grid_locations(image_height, image_width)\n",
    "    flattened_grid_locations = flatten_grid_locations(grid_locations, image_height, image_width)\n",
    "\n",
    "#     flattened_grid_locations = constant_op.constant(\n",
    "#         _expand_to_minibatch(flattened_grid_locations, batch_size), image.dtype)\n",
    "\n",
    "#     if clamp_boundaries:\n",
    "#       (dest_control_point_locations,\n",
    "#        control_point_flows) = _add_zero_flow_controls_at_boundary(\n",
    "#            dest_control_point_locations, control_point_flows, image_height,\n",
    "#            image_width, boundary_points_per_edge)\n",
    "\n",
    "    flattened_flows = interpolate_spline(\n",
    "        dest_control_point_locations,\n",
    "        control_point_flows,\n",
    "        flattened_grid_locations,\n",
    "        interpolation_order,\n",
    "        regularization_weight)\n",
    "    # CONTINUE FROM HERE AFTER  INTERPOLATE FUNC IS FINISHED\n",
    "    return flattened_flows\n",
    "\n",
    "    dense_flows = create_dense_flows(flattened_flows, batch_size, image_height, image_width)\n",
    "\n",
    "    warped_image = dense_image_warp(image, dense_flows)\n",
    "\n",
    "    return warped_image, dense_flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_grid_locations(image_height, image_width):\n",
    "    \"\"\"Wrapper for np.meshgrid.\"\"\"\n",
    "\n",
    "    y_range = np.linspace(0, image_height - 1, image_height)\n",
    "    x_range = np.linspace(0, image_width - 1, image_width)\n",
    "    y_grid, x_grid = np.meshgrid(y_range, x_range, indexing='ij')\n",
    "    return np.stack((y_grid, x_grid), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_grid_locations(grid_locations, image_height, image_width):\n",
    "    return np.reshape(grid_locations, [image_height * image_width, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dense_flows(flattened_flows, batch_size, image_height, image_width):\n",
    "    # possibly .view\n",
    "    return torch.reshape(flattened_flows, [batch_size, image_height, image_width, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpolate Spline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_spline(train_points:torch.Tensor, train_values:torch.Tensor, query_points:torch.Tensor, order, regularization_weight=0.0,):\n",
    "    # First, fit the spline to the observed data.\n",
    "    w, v = solve_interpolation(train_points, train_values, order, regularization_weight)\n",
    "    # Then, evaluate the spline at the query locations.\n",
    "    query_values = apply_interpolation(query_points, train_points, w, v, order)\n",
    "\n",
    "    return query_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix A tensor([[[-0.]]]) torch.Size([1, 1, 1])\n",
      "Matrix B tensor([[[1., 6., 1.]]]) torch.Size([1, 1, 3])\n",
      "Left Block tensor([[[-0.],\n",
      "         [1.],\n",
      "         [6.],\n",
      "         [1.]]]) torch.Size([1, 4, 1])\n",
      "Num_B_Cols torch.Size([1, 1, 3])\n",
      "Right Block tensor([[[ 1.0000e+00,  6.0000e+00,  1.0000e+00],\n",
      "         [-1.7422e-11,  1.8778e-10, -7.2305e-11],\n",
      "         [-1.3256e-10,  2.6914e-11, -1.7892e-10],\n",
      "         [-8.3804e-12,  9.6467e-11, -2.5977e-11]]]) torch.Size([1, 4, 3])\n",
      "LHS tensor([[[-0.0000e+00,  1.0000e+00,  6.0000e+00,  1.0000e+00],\n",
      "         [ 1.0000e+00, -1.7422e-11,  1.8778e-10, -7.2305e-11],\n",
      "         [ 6.0000e+00, -1.3256e-10,  2.6914e-11, -1.7892e-10],\n",
      "         [ 1.0000e+00, -8.3804e-12,  9.6467e-11, -2.5977e-11]]]) torch.Size([1, 4, 4])\n",
      "RHS tensor([[[0., 3.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]]]) torch.Size([1, 4, 2])\n",
      "tensor([[[ 0.0000e+00, -1.1849e-10]]])\n",
      "tensor([[[  0.0000, -12.8733],\n",
      "         [  0.0000,   1.6762],\n",
      "         [ -0.0000,   5.8163]]])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "apply_interpolation() takes 0 positional arguments but 5 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-222-7ceecf82859b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msparse_image_warp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspectro\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_pts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest_pts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-166-862810fbf2e0>\u001b[0m in \u001b[0;36msparse_image_warp\u001b[0;34m(img_tensor, source_control_point_locations, dest_control_point_locations, interpolation_order, regularization_weight, num_boundaries_points)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mflattened_grid_locations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0minterpolation_order\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         regularization_weight)\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0;31m# CONTINUE FROM HERE AFTER  INTERPOLATE FUNC IS FINISHED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mflattened_flows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-170-4c0be4e382ce>\u001b[0m in \u001b[0;36minterpolate_spline\u001b[0;34m(train_points, train_values, query_points, order, regularization_weight)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msolve_interpolation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_points\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregularization_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# Then, evaluate the spline at the query locations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mquery_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapply_interpolation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_points\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_points\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mquery_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: apply_interpolation() takes 0 positional arguments but 5 were given"
     ]
    }
   ],
   "source": [
    "sparse_image_warp(spectro, src_pts, dest_pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_interpolation(train_points, train_values, order, regularization_weight):\n",
    "    b, n, d = train_points.shape\n",
    "    k = train_values.shape[-1]\n",
    "\n",
    "    # First, rename variables so that the notation (c, f, w, v, A, B, etc.)\n",
    "    # follows https://en.wikipedia.org/wiki/Polyharmonic_spline.\n",
    "    # To account for python style guidelines we use\n",
    "    # matrix_a for A and matrix_b for B.\n",
    "    \n",
    "    c = train_points\n",
    "    f = train_values.float()\n",
    "    \n",
    "    matrix_a = phi(cross_squared_distance_matrix(c,c), order).unsqueeze(0)  # [b, n, n]\n",
    "    print('Matrix A', matrix_a, matrix_a.shape)\n",
    "#     if regularization_weight > 0:\n",
    "#         batch_identity_matrix = array_ops.expand_dims(\n",
    "#           linalg_ops.eye(n, dtype=c.dtype), 0)\n",
    "#         matrix_a += regularization_weight * batch_identity_matrix\n",
    "\n",
    "    # Append ones to the feature values for the bias term in the linear model.\n",
    "    ones = torch.ones(1, dtype=src_pts.dtype).view([-1, 1, 1])\n",
    "    matrix_b = torch.cat((c, ones), 2).float()  # [b, n, d + 1]\n",
    "    print('Matrix B', matrix_b, matrix_b.shape)\n",
    "\n",
    "    # [b, n + d + 1, n]\n",
    "    left_block = torch.cat((matrix_a, torch.transpose(matrix_b, 2, 1)), 1)\n",
    "    print('Left Block', left_block, left_block.shape)\n",
    "\n",
    "    num_b_cols = matrix_b.shape[2]  # d + 1\n",
    "    print('Num_B_Cols', matrix_b.shape)\n",
    "    #     lhs_zeros = torch.zeros((b, num_b_cols, num_b_cols), dtype=train_points.dtype).float()\n",
    "\n",
    "    # In Tensorflow, zeros are used here. Pytorch gesv fails with zeros for some reason we don't understand.\n",
    "    # So instead we use very tiny randn values (variance of one, zero mean) on one side of our multiplication.\n",
    "    lhs_zeros = torch.randn((b, num_b_cols, num_b_cols)) / 1e10\n",
    "    right_block = torch.cat((matrix_b, lhs_zeros),\n",
    "                                   1)  # [b, n + d + 1, d + 1]\n",
    "    print('Right Block', right_block, right_block.shape)\n",
    "    lhs = torch.cat((left_block, right_block),\n",
    "                           2)  # [b, n + d + 1, n + d + 1]\n",
    "    print('LHS', lhs, lhs.shape)\n",
    "\n",
    "    rhs_zeros = torch.zeros((b, d + 1, k), dtype=train_points.dtype).float()\n",
    "    rhs = torch.cat((f, rhs_zeros), 1)  # [b, n + d + 1, k]\n",
    "    print('RHS', rhs, rhs.shape)\n",
    "\n",
    "    # Then, solve the linear system and unpack the results.\n",
    "    X, LU = torch.gesv(rhs, lhs)\n",
    "    w = X[:, :n, :]\n",
    "    v = X[:, n:, :]\n",
    "\n",
    "    return w, v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_squared_distance_matrix(x, y):\n",
    "    \"\"\"Pairwise squared distance between two (batch) matrices' rows (2nd dim).\n",
    "        Computes the pairwise distances between rows of x and rows of y\n",
    "        Args:\n",
    "        x: [batch_size, n, d] float `Tensor`\n",
    "        y: [batch_size, m, d] float `Tensor`\n",
    "        Returns:\n",
    "        squared_dists: [batch_size, n, m] float `Tensor`, where\n",
    "        squared_dists[b,i,j] = ||x[b,i,:] - y[b,j,:]||^2\n",
    "    \"\"\"\n",
    "    x_norm_squared = torch.sum(torch.mul(x, x))\n",
    "    y_norm_squared = torch.sum(torch.mul(y, y))\n",
    "\n",
    "    x_y_transpose = torch.matmul(x.squeeze(0), y.squeeze(0).transpose(0,1))\n",
    "    \n",
    "    # squared_dists[b,i,j] = ||x_bi - y_bj||^2 = x_bi'x_bi- 2x_bi'x_bj + x_bj'x_bj\n",
    "    squared_dists = x_norm_squared - 2 * x_y_transpose + y_norm_squared\n",
    "\n",
    "    return squared_dists.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9.]])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for [1,3] a [1,6]\n",
    "cross_squared_distance_matrix(src_pts, dest_pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phi(r, order):\n",
    "    \"\"\"Coordinate-wise nonlinearity used to define the order of the interpolation.\n",
    "    See https://en.wikipedia.org/wiki/Polyharmonic_spline for the definition.\n",
    "    Args:\n",
    "    r: input op\n",
    "    order: interpolation order\n",
    "    Returns:\n",
    "    phi_k evaluated coordinate-wise on r, for k = r\n",
    "    \"\"\"\n",
    "    EPSILON=torch.tensor(1e-10)\n",
    "    # using EPSILON prevents log(0), sqrt0), etc.\n",
    "    # sqrt(0) is well-defined, but its gradient is not\n",
    "    if order == 1:\n",
    "        r = torch.max(r, EPSILON)\n",
    "        r = torch.sqrt(r)\n",
    "        return r\n",
    "    elif order == 2:\n",
    "        return 0.5 * r * torch.log(torch.max(r, EPSILON))\n",
    "    elif order == 4:\n",
    "        return 0.5 * torch.square(r) * torch.log(torch.max(r, EPSILON))\n",
    "    elif order % 2 == 0:\n",
    "        r = torch.max(r, EPSILON)\n",
    "        return 0.5 * torch.pow(r, 0.5 * order) * torch.log(r)\n",
    "    else:\n",
    "        r = torch.max(r, EPSILON)\n",
    "        return torch.pow(r, 0.5 * order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9.8875]])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phi(cross_squared_distance_matrix(src_pts, dest_pts), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_interpolation():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 4]) torch.Size([1, 4, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 4, 2]), tensor([[[ 6.0000,  0.0000,  1.0000,  0.0000],\n",
       "          [ 0.1667,  1.0000, -0.1667,  0.0000],\n",
       "          [ 0.1667,  1.0000,  6.0000,  1.0000],\n",
       "          [ 0.1667,  0.0000, -0.0278,  1.0278]]]))"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_A = torch.tensor([[[1., 1., 6., 1.],\n",
    "         [1., 1., 0., 0.],\n",
    "         [6., 0., 1., 0.],\n",
    "         [1., 0., 0., 1.]]])\n",
    "test_B = torch.tensor([[[-1.,  3.],\n",
    "         [ 0.,  0.],\n",
    "         [ 0.,  0.],\n",
    "         [ 0.,  0.]]])\n",
    "print(test_A.shape, test_B.shape)\n",
    "X, LU = torch.gesv(test_B, test_A)\n",
    "X.shape, LU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spec_augment",
   "language": "python",
   "name": "spec_augment"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
